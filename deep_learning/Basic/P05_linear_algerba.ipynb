{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "postal-uncle",
   "metadata": {},
   "source": [
    "### 创建矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "massive-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.arange(20).reshape(5,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-firmware",
   "metadata": {},
   "source": [
    "### 矩阵的转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coordinated-mattress",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-drove",
   "metadata": {},
   "source": [
    "### 两个矩阵按元素的乘法称为 哈达玛积 （Hadamard product）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "external-jonathan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   4,   9],\n",
       "        [ 16,  25,  36,  49],\n",
       "        [ 64,  81, 100, 121],\n",
       "        [144, 169, 196, 225],\n",
       "        [256, 289, 324, 361]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.clone()\n",
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-chicago",
   "metadata": {},
   "source": [
    "### sum of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "theoretical-depression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor(6.))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of the elements\n",
    "x = torch.arange(4, dtype = torch.float32)\n",
    "x, x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minimal-neighbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([40, 45, 50, 55]), tensor(190))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis = 0), a.sum(axis = [0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-liverpool",
   "metadata": {},
   "source": [
    "### keep the dimension while do sum or mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continuing-wholesale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19]]),\n",
       " tensor([[ 6],\n",
       "         [22],\n",
       "         [38],\n",
       "         [54],\n",
       "         [70]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = a.sum(axis = 1, keepdims = True)\n",
    "a, sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "round-affairs",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
       "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
       "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
       "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
       "        [0.2286, 0.2429, 0.2571, 0.2714]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a / sum_A # broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-berlin",
   "metadata": {},
   "source": [
    "### 点积是相同位置的按元素乘积的和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hazardous-attendance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.ones(4, dtype = torch.float32)\n",
    "x, y , torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-compact",
   "metadata": {},
   "source": [
    "### 我们可以通过执行按元素乘法，然后进行求和来表示两个向量的点积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "previous-recruitment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "graduate-envelope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication\n",
    "a.shape, x.shape, torch.mv(a.float(),x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-olive",
   "metadata": {},
   "source": [
    "### L2范数是向量元素平方和的平方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "actual-native",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0,-4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-buffer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
